{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a9787b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORT LIBS ####\n",
    "import subprocess, os, glob\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio import motifs\n",
    "\n",
    "#### DEFINE FUNCTIONS ####\n",
    "## MISC: Data processing\n",
    "def rev_comp(seq):\n",
    "    five_prime = Seq(seq)\n",
    "    rc = str(five_prime.reverse_complement())\n",
    "    return rc\n",
    "\n",
    "def write_df_to_fasta(df, title, col=\"Kmer\"):\n",
    "    for_fasta = zip(np.arange(0, len(list(df[col]))), list(df[col]))\n",
    "    with open(f\"{title}.fa\", \"w\") as f:\n",
    "        for seq in for_fasta:\n",
    "            f.write(f\">{seq[0]}\\n\")\n",
    "            f.write(f\"{seq[1]}\\n\")\n",
    "    return None\n",
    "\n",
    "def get_fasta_seqs(fasta_file):\n",
    "    sequences = []\n",
    "    # Open and parse the FASTA file\n",
    "    with open(fasta_file, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            sequences.append(record.seq)\n",
    "            \n",
    "    return sequences\n",
    "\n",
    "def fastp_merge_reads(r1, r2, base):\n",
    "    merged_file = f\"{base}_merged_reads.fastq.gz\"\n",
    "    fastp_str = (\n",
    "        f\"fastp --in1={r1} --in2={r2} --merge --out1={base}_trimmed_R1.fastq.gz --out2={base}_trimmed_R2.fastq.gz \"\n",
    "        f\"--merged_out={merged_file} --html={base}_report.html --json={base}report.json\"\n",
    "    )\n",
    "    print(fastp_str)\n",
    "    os.system(fastp_str)\n",
    "    return merged_file\n",
    "\n",
    "def grep_fastq(fasta, left_pat, right_pat, length_variable_region, out_file_name):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        - fasta: REQUIRED. gzip or uncompressed accepted\n",
    "        - left_pat: REQUIRED. 5'/left-flanking sequence for variable region\n",
    "        - right_pat: REQUIRED. 3'/right-flanking sequence for variable region\n",
    "        - length_variable_region: REQUIRED. EXACT number of N's comprising variable region\n",
    "                    between the flanking sequences\n",
    "        - out_file_name: REQUIRED. Name for output file containing matches\n",
    "    OUTPUTS:\n",
    "        - out_file_name: Name of file saved to store matches\n",
    "        - sequencing_depth: Number of total reads in fasta file\n",
    "        - number_of_pattern_matches: Total number of grep hits (NOT unique number of patterns)\n",
    "    \"\"\"\n",
    "    # IF GZIP\n",
    "    if fasta.endswith(\".gz\"):\n",
    "        # GET SEQUENCING DEPTH\n",
    "        sequencing_depth = int(subprocess.check_output(\n",
    "            f\"zcat {fasta}|wc -l\", shell=True).decode('utf-8')) / 2\n",
    "\n",
    "        # GET MATCHES\n",
    "        grep_str = (\n",
    "            f\"zcat {fasta}| grep -Eo \"\n",
    "            f\"'{left_pat}[A|T|G|C]{{{length_variable_region}}}{right_pat}' \"\n",
    "            f\"| sed -e 's/{right_pat}$//' | sed -e 's/^{left_pat}//' > {out_file_name}\"\n",
    "        )\n",
    "        print(grep_str)\n",
    "        subprocess.run(grep_str, shell=True)\n",
    "\n",
    "        # COUNT NUMBER OF MATCHES\n",
    "        number_of_pattern_matches = int(subprocess.check_output(\n",
    "            f\"wc -l {out_file_name}\", shell=True).decode('utf-8').split()[0])\n",
    "    # ELIF NOT COMPRESSED:\n",
    "    else:\n",
    "        # GET SEQUENCING DEPTH\n",
    "        sequencing_depth = int(subprocess.check_output(\n",
    "            f\"wc -l {fasta}\", shell=True).decode('utf-8').split()[0]) / 2\n",
    "\n",
    "        # GET MATCHES\n",
    "        grep_str = (\n",
    "            f\"grep -Eo '{left_pat}[A|T|G|C]{{{length_variable_region}}}{right_pat}' \"\n",
    "            f\"{fasta} | sed -e 's/{right_pat}$//' | sed -e 's/^{left_pat}//' > {out_file_name}\"\n",
    "        )\n",
    "        print(grep_str)\n",
    "        subprocess.run(grep_str, shell=True)\n",
    "\n",
    "        # COUNT NUMBER OF MATCHES\n",
    "        number_of_pattern_matches = int(subprocess.check_output(\n",
    "            f\"wc -l {out_file_name}\", shell=True).decode('utf-8').split()[0])\n",
    "\n",
    "    return out_file_name, sequencing_depth, number_of_pattern_matches\n",
    "\n",
    "\n",
    "# KMER FREQUENCY\n",
    "def get_kmer_frequency_dict(pam_match_file, sequencing_depth=None, reverse_complement=False,\n",
    "                            bc_trim_n_left=False, bc_trim_n_right=False):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        - pam_match_file: REQUIRED. Fasta or txt file of PAM pattern-matches. NOT FASTQ compatible.\n",
    "        - sequencing_depth: OPTIONAL. Default = None. Sequencing depth (int) for optional normalization.\n",
    "        - reverse_complement: OPTIONAL. Default = False. Option to reverse complement the PAM/grep output.\n",
    "        - bc_trim_n_left: OPTIONAL. Default = False. Option to trim N number of bases from 5'-end of PAM/grep output.\n",
    "                            Trim end as it relates to the PAM-match file, not reverse compliment.\n",
    "        - bc_trim_n_right: OPTIONAL. Default = False. Option to trim N number of bases from 3'-end of PAM/grep output.\n",
    "                            Trim end as it relates to the PAM-match file, not reverse compliment.\n",
    "\n",
    "    OUTPUT:\n",
    "        - kmer_freq_dict: Dictionary of kmer frequencies. Keys are the Kmer sequences.\n",
    "    \"\"\"\n",
    "    with open(pam_match_file, \"r\") as f:\n",
    "        pam_seqs = [x.replace(\"\\n\", \"\") for x in f.readlines() if not x.startswith(\">\")]\n",
    "\n",
    "    ## TRIM\n",
    "    if bc_trim_n_left:\n",
    "        pam_seqs = [x[bc_trim_n_left:] for x in pam_seqs]\n",
    "    if bc_trim_n_right:\n",
    "        pam_seqs = [x[:-1 * bc_trim_n_right] for x in pam_seqs]\n",
    "\n",
    "    ## COUNT\n",
    "    if sequencing_depth:\n",
    "        kmer_freq_dict = {k: v / sequencing_depth for k, v in Counter(pam_seqs).items()}\n",
    "    else:\n",
    "        kmer_freq_dict = dict(Counter(pam_seqs))\n",
    "\n",
    "    ## REVERSE COMPLEMENT\n",
    "    if reverse_complement:\n",
    "        kmer_freq_dict = {rev_comp(k): v for k, v in kmer_freq_dict.items()}\n",
    "\n",
    "    return kmer_freq_dict\n",
    "\n",
    "# NUCLEOTIDE FREQUENCY\n",
    "def get_nucleotide_frequency_dict(pam_match_file, length_variable_region=8, sequencing_depth=None,\n",
    "                                  reverse_complement=False, bc_trim_n_left=False, bc_trim_n_right=False):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        - pam_match_file: REQUIRED. Fasta or txt file of PAM pattern-matches. NOT FASTQ compatible.\n",
    "        - length_variable_region: REQUIRED. Default = 8. EXACT number of N's comprising variable region\n",
    "                            between the flanking sequences\n",
    "        - sequencing_depth: OPTIONAL. Default = None. Sequencing depth (int) for optional normalization.\n",
    "        - reverse_complement: OPTIONAL. Default = False. Option to reverse complement the PAM/grep output.\n",
    "        - bc_trim_n_left: OPTIONAL. Default = False. Option to trim N number of bases from 5'-end of PAM/grep output.\n",
    "                            Trim end as it relates to the PAM-match file, not reverse compliment.\n",
    "        - bc_trim_n_right: OPTIONAL. Default = False. Option to trim N number of bases from 3'-end of PAM/grep output.\n",
    "                            Trim end as it relates to the PAM-match file, not reverse compliment.\n",
    "\n",
    "    OUTPUT:\n",
    "        - kmer_freq_dict: Dictionary of kmer frequencies. Keys are the Kmer sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    nucleotide_frequency_dict = {}\n",
    "    nucleotide_order = [\"A\", \"C\", \"G\", \"T\"]\n",
    "\n",
    "    ## READ PAM FILE\n",
    "    with open(pam_match_file) as f:\n",
    "        pam_seqs = [x.replace(\"\\n\", \"\") for x in f.readlines() if not x.startswith(\">\")]\n",
    "\n",
    "    ## TRIM\n",
    "    if bc_trim_n_left:\n",
    "        pam_seqs = [x[bc_trim_n_left:] for x in pam_seqs]\n",
    "    if bc_trim_n_right:\n",
    "        pam_seqs = [x[:-1 * bc_trim_n_right] for x in pam_seqs]\n",
    "\n",
    "    ## REVERSE COMPLEMENT\n",
    "    if reverse_complement:  # Reverse complement sequence\n",
    "        pam_seqs = [rev_comp(x) for x in pam_seqs]\n",
    "\n",
    "    ## CALCULATE NUCLEOTIDE FREQUENCY AT EACH POSITION IN PAM\n",
    "    # GET PAM LENGTH FOR CALCULATION\n",
    "    if bc_trim_n_left or bc_trim_n_right:\n",
    "        pam_length = length_variable_region - bc_trim_n_left - bc_trim_n_right\n",
    "    else:\n",
    "        pam_length = length_variable_region\n",
    "\n",
    "    for i in range(pam_length):\n",
    "        if sequencing_depth:\n",
    "            temp_dict = {k: v / sequencing_depth for k, v in Counter([x[i] for x in pam_seqs]).items()}\n",
    "        else:\n",
    "            temp_dict = {k: v for k, v in Counter([x[i] for x in pam_seqs]).items()}\n",
    "\n",
    "        # ADD UNOBSERVED NUCLEOTIDES TO DICT\n",
    "        missing = [x for x in nucleotide_order if x not in temp_dict.keys()]\n",
    "        for m in missing:\n",
    "            temp_dict[m] = 0\n",
    "\n",
    "        nucleotide_frequency_dict[i] = temp_dict\n",
    "\n",
    "    return nucleotide_frequency_dict\n",
    "\n",
    "## PLOT LOGOS\n",
    "def logo_from_fasta(fasta, graph_title = \"Logo\", pam_len = 6, x_tick_list = False, \n",
    "                    to_save = True, out_name = False):\n",
    "    ## READ FASTA\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta, \"fasta\"):\n",
    "        sequences.append(str(record.seq))\n",
    "        \n",
    "    if len(sequences) == 0:\n",
    "        print(f\"!!!!!EMPTY FASTA:{fasta}\")\n",
    "        return None\n",
    "    \n",
    "    ## LOGOMAKER WORKFLOW\n",
    "    # GET COUNT MATRIX\n",
    "    counts_matrix = logomaker.alignment_to_matrix(sequences)\n",
    "    # GET FREQUENCIES\n",
    "    frequencies_matrix = logomaker.transform_matrix(counts_matrix, \n",
    "                                                    from_type='counts', \n",
    "                                                    to_type='probability',\n",
    "                                                    #background=4*[0.25], \n",
    "                                                    pseudocount=0.0 # Avoid pseudocounting PAMs not in NegCtrl\n",
    "                                                   )\n",
    "    # GET INFORMATION CONTENT\n",
    "    info_content_matrix = logomaker.transform_matrix(frequencies_matrix, \n",
    "                                                     from_type='probability', \n",
    "                                                     to_type='information', \n",
    "                                                     #background=4*[0.25], \n",
    "                                                     pseudocount=0.0 # Avoid pseudocounting PAMs not in NegCtrl\n",
    "                                                    )\n",
    "\n",
    "    ## PLOT LOGO\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[8, 6])\n",
    "    logo = logomaker.Logo(info_content_matrix,\n",
    "                          ax = ax, \n",
    "                          color_scheme= {\"A\":\"orange\", \"T\":\"orange\", \"C\":\"blue\", \"G\":\"blue\"}\n",
    "                          )\n",
    "    \n",
    "    # FORMAT\n",
    "    logo.ax.set_ylabel('Bits')\n",
    "    logo.ax.set_ylim([0, 2])\n",
    "    if x_tick_list:\n",
    "        x_tick_positions = range(0,len(x_tick_list))\n",
    "        x_tick_labels = x_tick_list\n",
    "        logo.ax.set_xticks(x_tick_positions)\n",
    "        logo.ax.set_xticklabels(x_tick_labels)\n",
    "    else:\n",
    "        x_tick_positions = range(0,pam_len)\n",
    "        x_tick_labels = range(-1*pam_len,0)\n",
    "        logo.ax.set_xticks(x_tick_positions)\n",
    "        logo.ax.set_xticklabels(x_tick_labels)\n",
    "    logo.ax.set_title(graph_title, size = 12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # SAVE: dpi\n",
    "    if to_save and out_name:\n",
    "        logo.fig.savefig(out_name, format = \"svg\", dpi = 400)\n",
    "    elif to_save and (out_name == False):\n",
    "        logo.fig.savefig(\"Logomaker_motif.fasta\", format = \"svg\", dpi = 400)\n",
    "        \n",
    "    return frequencies_matrix\n",
    "\n",
    "def pam_fold_change_logos(neg_ctrl_pam_file, \n",
    "                          test_condition_pam_file,\n",
    "                          fold_change_magnitudes=[2, 3, 5],\n",
    "                          depletion=True,\n",
    "                          use_pseudo_counts=False,\n",
    "                          length_variable_region=8,\n",
    "                          neg_ctrl_sequencing_depth=None,\n",
    "                          test_condition_sequencing_depth=None,\n",
    "                          reverse_complement=False,\n",
    "                          bc_trim_n_left=False,\n",
    "                          bc_trim_n_right=False,\n",
    "                          weblogo_graph_title=False,\n",
    "                          weblogo_x_axis_ticks=False,\n",
    "                          out_dir=None\n",
    "                          ):\n",
    "    \"\"\"\n",
    "    DESCRIPTION:\n",
    "        Plots classic weblogo (bits on y-axis), given extracted sequence matches from the targeting \n",
    "        and non-targeting conditions.\n",
    "    INPUTS:\n",
    "        - neg_ctrl_pam_file: REQUIRED. Fasta or txt file of negative-control PAM pattern-matches.\n",
    "                            NOT FASTQ compatible.\n",
    "        - test_condition_pam_file: REQUIRED. Fasta or txt file of test-condition PAM pattern-matches.\n",
    "                            NOT FASTQ compatible.\n",
    "        - fold_change_magnitudes: OPTIONAL. Default = [2, 3, 5]. List of log2 fold-change cutoffs for filtering\n",
    "                            PAMs prior to logo generation. ENTER POSITIVE VALUES ONLY. If running a depletion\n",
    "                            assay, set depletion == True in lieu of using negative values.\n",
    "        - depletion: OPTIONAL. Default = True. True implies a PAM depletion assay. Set equal to False for PAM\n",
    "                            enrichment assay.\n",
    "        - use_pseudo_counts: OPTIONAL. Default = False. Setting pseudocounts to True, will replace any PAM with\n",
    "                            count 0 with 1/number_reads_in_targeting_sample_fastq. If pseudocounts is False, \n",
    "                            then only PAM sequences found in BOTH the negative control and test condition \n",
    "                            will use for the analysis.\n",
    "        - length_variable_region: OPTIONAL. Default = 8. EXACT number of N's comprising variable region\n",
    "                            between the flanking sequences in the screening construct.\n",
    "        - neg_ctrl_sequencing_depth: OPTIONAL. Default = None. Negative-control sequencing depth (int)\n",
    "                            for optional normalization. If set to None, PAM counts will not be normalized.\n",
    "        - test_condition_sequencing_depth: OPTIONAL. Default = None. Test-condition sequencing depth (int)\n",
    "                            for optional normalization. If set to None, PAM counts will not be normalized.\n",
    "        - reverse_complement: OPTIONAL. Default = False. Option to reverse complement the PAM/grep output.\n",
    "        - bc_trim_n_left: OPTIONAL. Default = False. Option to trim N number of bases from 5'-end of \n",
    "                            PAM/grep output. Trim end as it relates to the PAM-match file, \n",
    "                            not reverse compliment.\n",
    "        - bc_trim_n_right: OPTIONAL. Default = False. Option to trim N number of bases from 3'-end of \n",
    "                            PAM/grep output. Trim end as it relates to the PAM-match file, not \n",
    "                            reverse compliment.\n",
    "        - weblogo_x_axis_ticks: OPTIONAL. Default = False. X-axis tick marks for weblogo.\n",
    "        - save_weblogo: OPTIONAL. Default = False. Set to True, in order to save nucleotide-proportion graph.\n",
    "                            Bit-Weblogos automatically save.\n",
    "        - out_dir: OPTIONAL. Default = False. Directory for saving plots. Otherwise outputs to PWD.\n",
    "    OUTPUTS:\n",
    "        - fold_dfs: Dictionary of PAM frequencies at each specified fold-change.\n",
    "        - freq_dfs: Dictionary of nucleotide frequencies at each position of PAM for each specified fold-change filter.\n",
    "        - count_df: Dataframe of all PAM counts.\n",
    "    \"\"\"\n",
    "\n",
    "    #### SETUP ####\n",
    "    if out_dir:\n",
    "        if not out_dir.endswith(\"/\"):\n",
    "            out_dir = out_dir + \"/\" # Enforce terminal \"/\"\n",
    "\n",
    "    ## GET PAM LENGTH FOR CALCULATION\n",
    "    if bc_trim_n_left or bc_trim_n_right:\n",
    "        pam_length = length_variable_region - bc_trim_n_left - bc_trim_n_right\n",
    "    else:\n",
    "        pam_length = length_variable_region\n",
    "\n",
    "    ## GET KMER FREQUENCIES\n",
    "    ntc = get_kmer_frequency_dict(neg_ctrl_pam_file,\n",
    "                                  sequencing_depth=neg_ctrl_sequencing_depth,\n",
    "                                  reverse_complement=reverse_complement,\n",
    "                                  bc_trim_n_left=bc_trim_n_left,\n",
    "                                  bc_trim_n_right=bc_trim_n_right)\n",
    "    ntc_df = pd.DataFrame({\"Kmer\": ntc.keys(), \"Count\": ntc.values()})\n",
    "\n",
    "    test = get_kmer_frequency_dict(test_condition_pam_file,\n",
    "                                   sequencing_depth=test_condition_sequencing_depth,\n",
    "                                   reverse_complement=reverse_complement,\n",
    "                                   bc_trim_n_left=bc_trim_n_left,\n",
    "                                   bc_trim_n_right=bc_trim_n_right)\n",
    "    test_df = pd.DataFrame({\"Kmer\": test.keys(), \"Count\": test.values()})\n",
    "\n",
    "    ## OPTIONAL PSEUDO-COUNTS:\n",
    "    \"\"\"\n",
    "        - If PAM missing in one experiment, update the NAN to 1 or 1/seq_depth_condition_with_NAN.\n",
    "        - ONLY implement pseudo-counts on for the union of PAMs found test and negative-control samples, \n",
    "          NOT all 4**N combinations. This helps limit intrinisic bias for in vivo experiments and \n",
    "          substrate libraries.\n",
    "    \"\"\"\n",
    "    if use_pseudo_counts:\n",
    "        count_df = pd.merge(ntc_df, test_df, on=\"Kmer\", suffixes=[\"_NTC\", \"_Test\"], how=\"outer\")\n",
    "\n",
    "        ntc_cols = [x for x in count_df.columns if x.endswith(\"_NTC\")]\n",
    "        if test_condition_sequencing_depth != None:\n",
    "            count_df[ntc_cols] = count_df[ntc_cols].fillna(1 / test_condition_sequencing_depth)\n",
    "        else:\n",
    "            count_df[ntc_cols] = count_df[ntc_cols].fillna(1)\n",
    "        \n",
    "        test_cols = [x for x in count_df.columns if x.endswith(\"_Test\")]\n",
    "        if test_condition_sequencing_depth != None:\n",
    "            count_df[test_cols] = count_df[test_cols].fillna(1 / test_condition_sequencing_depth)\n",
    "        else:\n",
    "            count_df[test_cols] = count_df[test_cols].fillna(1)\n",
    "    else:  # Else, don't apply pseudocounts and prevent NAN's with inner-join\n",
    "        count_df = pd.merge(ntc_df, test_df, on=\"Kmer\", suffixes=[\"_NTC\", \"_Test\"], how=\"inner\")\n",
    "\n",
    "    ## CALCULATE FOLD-CHANGES\n",
    "    count_df[\"Log2_Fold_Change\"] = np.log2(count_df.Count_Test / count_df.Count_NTC)\n",
    "\n",
    "    ## FILTER ON DEPLETION/ENRICHMENT CUTOFFS\n",
    "    if depletion:\n",
    "        fold_dfs = {f\"{fc}\": count_df.loc[(count_df.Log2_Fold_Change <= -1 * fc)] \\\n",
    "                    for fc in fold_change_magnitudes}\n",
    "    else:  # Else enrichment analysis\n",
    "        fold_dfs = {f\"{fc}\": count_df.loc[(count_df.Log2_Fold_Change >= 1 * fc)] \\\n",
    "                    for fc in fold_change_magnitudes}\n",
    "    print(fold_dfs)\n",
    "\n",
    "    #### GRAPH LOGOS ####\n",
    "    freq_dfs = []        \n",
    "    fc_counter = 0\n",
    "    \n",
    "    ## PLOT LOGOS AT EACH Log2FC Cutoff\n",
    "    for k, v in fold_dfs.items():\n",
    "        temp_df = v  # Select fold-change-filtered df for graphing\n",
    "        print(f\"\\n#### N FC{float(k):0.3f}x Motifs: {temp_df.shape[0]}\", temp_df)\n",
    "\n",
    "        ## TABULATE POSITION-WISE FREQUENCY FOR SPECIFIC FOLD-CHANGE FILTER\n",
    "        array_dict = {}\n",
    "        rows = []\n",
    "        nucleotide_order = [\"A\", \"C\", \"G\", \"T\"]\n",
    "\n",
    "        for i in range(pam_length):\n",
    "            array_dict[i] = Counter([x[i] for x in list(temp_df.Kmer)])\n",
    "\n",
    "        for i in range(pam_length):\n",
    "            v = array_dict[i]\n",
    "            row_sum = sum(v.values())\n",
    "            if row_sum == 0:\n",
    "                rows.append(np.zeros(4))\n",
    "            else:\n",
    "                row = [v[n] / row_sum for n in nucleotide_order]\n",
    "                rows.append(row)\n",
    "\n",
    "        freq_df = pd.DataFrame(rows, columns=nucleotide_order)\n",
    "        freq_dfs.append(freq_df)\n",
    "\n",
    "        ## PLOT WEB LOGO\n",
    "        # Format graph output\n",
    "        fc_str = str(f\"{fold_change_magnitudes[fc_counter]:0.4f}\").replace('.', 'Pt')\n",
    "        sample = test_condition_pam_file.split(\"/\")[-1].split(\".\")[0].\\\n",
    "                         replace(' ', '_').replace('-', '_')\n",
    "        ctrl = neg_ctrl_pam_file.split(\"/\")[-1].split(\".\")[0].replace(' ', '_').replace('-', '_')\n",
    "        file_base = f\"Weblogo_{sample}_vs_{ctrl}_FC{fc_str}\"\n",
    "            \n",
    "        if out_dir:\n",
    "            file_base = f\"{out_dir}{file_base.replace('.fa', '')}\"\n",
    "\n",
    "        # Save Fasta of PAMs at specific fold-change\n",
    "        print(f\"## SAVING FOLD-CHANGE FASTA: {file_base}.fa\")\n",
    "        write_df_to_fasta(df=temp_df, title=f\"{file_base}\")\n",
    "        \n",
    "        # Setup formatting for weblogo graph\n",
    "        if not weblogo_x_axis_ticks:\n",
    "            weblogo_x_axis_ticks = ', '.join([str(-i) for i in range(1, pam_length + 1)][::-1])\n",
    "        if not weblogo_graph_title:\n",
    "            weblogo_graph_title = f\"{fc_str}XFC\\n(n = {temp_df.shape[0]})\"\n",
    "        print(f\"{fold_change_magnitudes[fc_counter]}\")\n",
    "            \n",
    "        logo_from_fasta(fasta = f\"{file_base}.fa\", graph_title = weblogo_graph_title, \n",
    "                        pam_len=pam_length, to_save=True, out_name=file_base)\n",
    "        print(f\"## SAVING BIT-WEBLOGO: {file_base}.svg\")\n",
    "        \n",
    "        fc_counter+=1\n",
    "\n",
    "    return fold_dfs, freq_dfs, count_df\n",
    "\n",
    "def nonparametric_ci_of_mean(data_array, n_iterations = 1000, alpha = 0.1, two_tail = False, mean = True):\n",
    "    # Perform boostrapping\n",
    "    boot_samples = []\n",
    "    for _ in range(n_iterations):\n",
    "        # RANDOM SAMPLE WITH REPLACEMENT\n",
    "        boot_sample = np.random.choice(data_array, size=len(data_array), replace=True)\n",
    "        boot_samples.append(boot_sample)\n",
    "\n",
    "    # MEAN CI\n",
    "    if mean:\n",
    "        if two_tail:\n",
    "            # Calculate the lower and upper bounds of the confidence interval\n",
    "            boot_means = np.mean(boot_samples, axis=1)\n",
    "            lower_bound = np.percentile(boot_means, alpha/2)\n",
    "            upper_bound = np.percentile(boot_means, 100-alpha/2)\n",
    "            return (lower_bound, upper_bound)\n",
    "        else:\n",
    "            boot_means = np.mean(boot_samples, axis=1)\n",
    "            lower_bound = np.percentile(boot_means, alpha)\n",
    "            return (lower_bound)\n",
    "    # MIN CI\n",
    "    else:\n",
    "        if two_tail:\n",
    "            # Calculate the lower and upper bounds of the confidence interval\n",
    "            boot_mins = np.min(boot_samples, axis=1)\n",
    "            lower_bound = np.percentile(boot_mins, alpha/2)\n",
    "            upper_bound = np.percentile(boot_mins, 100-alpha/2)\n",
    "            return (lower_bound, upper_bound)\n",
    "        else:\n",
    "            boot_mins = np.min(boot_samples, axis=1)\n",
    "            lower_bound = np.percentile(boot_mins, alpha)\n",
    "            return (lower_bound)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e6588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GET DATA AND SET VARIABLES ####\n",
    "## DIRECTORIES\n",
    "pwd = \"/groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/\"\n",
    "results_dir = \"/groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/Results/\"\n",
    "data_dir = \"/groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/FASTQS/\"\n",
    "out_dir = f\"{pwd}Logo_Output/\"\n",
    "\n",
    "## READS\n",
    "fastqs = [x for x in glob.glob(f\"{data_dir}/*/*.gz\")]\n",
    "r1_suffix = \"_L001_R1_001.fastq.gz\"\n",
    "r2_suffix = \"_L001_R2_001.fastq.gz\"\n",
    "base_files = [x.replace(r1_suffix, \"\") for x in fastqs if r1_suffix in x]\n",
    "base_ids = [x.split(\"/\")[-1].replace(r1_suffix, \"\") for x in fastqs if r1_suffix in x]\n",
    "\n",
    "## DETAILS FOR REGEX: Define flanking regions for 4N Variable region\n",
    "left_flank = \"TTTTT\"\n",
    "right_flank = \"CGAGT\"\n",
    "len_variable = 4\n",
    "\n",
    "# DEFINE CONTROLS: Match targeting samples with original substrate library (\"Amy1Libonly_S1\")\n",
    "control_dict = {\"Amy5TR1W1_S5\":\"Amy1Libonly_S1\", \n",
    "                \"Amy4TWT_S4\":\"Amy1Libonly_S1\",\n",
    "                \"Amy2NTWT_S2\":\"Amy1Libonly_S1\", # Check for technical bias\n",
    "                \"Amy3NTR1W1_S3\":\"Amy1Libonly_S1\", # Check for technical bias\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003468de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zcat /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/FASTQS/Amy2NTWT_L1_ds.fe4be173d93a4e6fb36ccf7e52a45c50/Amy2NTWT_S2_merged_reads.fastq.gz| grep -Eo 'TTTTT[A|T|G|C]{4}CGAGT' | sed -e 's/CGAGT$//' | sed -e 's/^TTTTT//' > /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/Results/Amy2NTWT_S2_matches.txt\n",
      "zcat /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/FASTQS/Amy1Libonly_L1_ds.0f546033cc7844a19aea680acba40d6b/Amy1Libonly_S1_merged_reads.fastq.gz| grep -Eo 'TTTTT[A|T|G|C]{4}CGAGT' | sed -e 's/CGAGT$//' | sed -e 's/^TTTTT//' > /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/Results/Amy1Libonly_S1_matches.txt\n",
      "zcat /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/FASTQS/Amy4TWT_L1_ds.3667e07b117a4ebc9638504bed6d04db/Amy4TWT_S4_merged_reads.fastq.gz| grep -Eo 'TTTTT[A|T|G|C]{4}CGAGT' | sed -e 's/CGAGT$//' | sed -e 's/^TTTTT//' > /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/Results/Amy4TWT_S4_matches.txt\n",
      "zcat /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/FASTQS/Amy3NTR1W1_L1_ds.10af32d417204708a1f572605494ae56/Amy3NTR1W1_S3_merged_reads.fastq.gz| grep -Eo 'TTTTT[A|T|G|C]{4}CGAGT' | sed -e 's/CGAGT$//' | sed -e 's/^TTTTT//' > /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/Results/Amy3NTR1W1_S3_matches.txt\n",
      "zcat /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/FASTQS/Amy5TR1W1_L1_ds.f086dd43710a4894a86c0d9e4727aea4/Amy5TR1W1_S5_merged_reads.fastq.gz| grep -Eo 'TTTTT[A|T|G|C]{4}CGAGT' | sed -e 's/CGAGT$//' | sed -e 's/^TTTTT//' > /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/GeoR1W1_Amy/Results/Amy5TR1W1_S5_matches.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Amy2NTWT_S2': [5928042.0, 2941051],\n",
       " 'Amy1Libonly_S1': [6319458.0, 3134270],\n",
       " 'Amy4TWT_S4': [8353252.0, 4144283],\n",
       " 'Amy3NTR1W1_S3': [5970588.0, 2960647],\n",
       " 'Amy5TR1W1_S5': [7402122.0, 3671516]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### MERGE READS AND REGEX-EXTRACT PAMS ####\n",
    "\n",
    "## MERGE FASTQS\n",
    "merged_reads = [x for x in glob.glob(f\"{data_dir}/*/*_merged_reads.fastq.gz\", recursive=True)]\n",
    "merged_reads = []\n",
    "\n",
    "for base in base_files:\n",
    "    temp_merged = fastp_merge_reads(r1=f\"{base}{r1_suffix}\", r2=f\"{base}{r2_suffix}\", base = base)\n",
    "    merged_reads.append(temp_merged)\n",
    "\n",
    "## GREP MERGED READS\n",
    "seq_depth_stats = {}\n",
    "match_files = []\n",
    "\n",
    "for merged in merged_reads: \n",
    "    base = merged.split(\"/\")[-1].replace(\"_merged_reads.fastq.gz\", \"\")\n",
    "    out = results_dir + base + \"_matches.txt\"\n",
    "    \n",
    "    ## GREP\n",
    "    out_file_name, sequencing_depth, number_of_pattern_matches = grep_fastq(fasta=merged, \n",
    "                                                                            left_pat=left_flank, \n",
    "                                                                            right_pat=right_flank, \n",
    "                                                                            length_variable_region=len_variable, \n",
    "                                                                            out_file_name=out\n",
    "                                                                           )\n",
    "    seq_depth_stats[base] = [sequencing_depth, number_of_pattern_matches]\n",
    "    match_files.append(out_file_name)\n",
    "    \n",
    "seq_depth_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a6573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1':     Kmer  Count_NTC  Count_Test  Log2_Fold_Change\n",
      "56  CTAA   0.001783    0.000782         -1.188849\n",
      "58  CGAA   0.001263    0.000600         -1.073967, '2': Empty DataFrame\n",
      "Columns: [Kmer, Count_NTC, Count_Test, Log2_Fold_Change]\n",
      "Index: []}\n",
      "\n",
      "#### N FC1.000x Motifs: 2     Kmer  Count_NTC  Count_Test  Log2_Fold_Change\n",
      "56  CTAA   0.001783    0.000782         -1.188849\n",
      "58  CGAA   0.001263    0.000600         -1.073967\n",
      "## SAVING FOLD-CHANGE FASTA: /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy5TR1W1_S5_matches_vs_Amy1Libonly_S1_matches_FC1Pt0000.fa\n",
      "1\n",
      "## SAVING BIT-WEBLOGO: /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy5TR1W1_S5_matches_vs_Amy1Libonly_S1_matches_FC1Pt0000.svg\n",
      "\n",
      "#### N FC2.000x Motifs: 0 Empty DataFrame\n",
      "Columns: [Kmer, Count_NTC, Count_Test, Log2_Fold_Change]\n",
      "Index: []\n",
      "## SAVING FOLD-CHANGE FASTA: /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy5TR1W1_S5_matches_vs_Amy1Libonly_S1_matches_FC2Pt0000.fa\n",
      "2\n",
      "!!!!!EMPTY FASTA:/groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy5TR1W1_S5_matches_vs_Amy1Libonly_S1_matches_FC2Pt0000.fa\n",
      "## SAVING BIT-WEBLOGO: /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy5TR1W1_S5_matches_vs_Amy1Libonly_S1_matches_FC2Pt0000.svg\n",
      "{'1': Empty DataFrame\n",
      "Columns: [Kmer, Count_NTC, Count_Test, Log2_Fold_Change]\n",
      "Index: [], '2': Empty DataFrame\n",
      "Columns: [Kmer, Count_NTC, Count_Test, Log2_Fold_Change]\n",
      "Index: []}\n",
      "\n",
      "#### N FC1.000x Motifs: 0 Empty DataFrame\n",
      "Columns: [Kmer, Count_NTC, Count_Test, Log2_Fold_Change]\n",
      "Index: []\n",
      "## SAVING FOLD-CHANGE FASTA: /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy4TWT_S4_matches_vs_Amy1Libonly_S1_matches_FC1Pt0000.fa\n",
      "1\n",
      "!!!!!EMPTY FASTA:/groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy4TWT_S4_matches_vs_Amy1Libonly_S1_matches_FC1Pt0000.fa\n",
      "## SAVING BIT-WEBLOGO: /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy4TWT_S4_matches_vs_Amy1Libonly_S1_matches_FC1Pt0000.svg\n",
      "\n",
      "#### N FC2.000x Motifs: 0 Empty DataFrame\n",
      "Columns: [Kmer, Count_NTC, Count_Test, Log2_Fold_Change]\n",
      "Index: []\n",
      "## SAVING FOLD-CHANGE FASTA: /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy4TWT_S4_matches_vs_Amy1Libonly_S1_matches_FC2Pt0000.fa\n",
      "2\n",
      "!!!!!EMPTY FASTA:/groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy4TWT_S4_matches_vs_Amy1Libonly_S1_matches_FC2Pt0000.fa\n",
      "## SAVING BIT-WEBLOGO: /groups/doudna/projects/mtrinidad_projects/Geo_Cas9_Indel_HDR_KC/Finalized_Code_for_Manuscript/Logo_Output/Weblogo_Amy4TWT_S4_matches_vs_Amy1Libonly_S1_matches_FC2Pt0000.svg\n"
     ]
    }
   ],
   "source": [
    "#### GET FOLD CHANGES AND EXPLORATORY LOGOS ####\n",
    "\"\"\"\n",
    "- Calculate Log2Fold Change against construct library (\"Amy1Libonly_S1\")\n",
    "- Generate Log2 Fold-change dataframes for later processing\n",
    "\"\"\"\n",
    "\n",
    "fold_dfs = {}\n",
    "freq_dfs = {} \n",
    "count_dfs = {}\n",
    "cis = {}\n",
    "\n",
    "## FOR EACH TARGETING SAMPLE, CALCULATE FOLDCHANGE RELATIVE TO SUBSTRATE LIBRARY\n",
    "for base in control_dict.keys(): \n",
    "    test_condition_pam_file = f\"{results_dir}{base}_matches.txt\"\n",
    "    neg_ctrl = control_dict[base]\n",
    "    neg_ctrl_pam_file = f\"{results_dir}{neg_ctrl}_matches.txt\"\n",
    "    \n",
    "    ## GET PAM FOLDCHANGES\n",
    "    fold_df, freq_df, count_df = pam_fold_change_logos(neg_ctrl_pam_file, \n",
    "                                                       test_condition_pam_file,\n",
    "                                                       fold_change_magnitudes=[1, 2], # log2 fold-changes\n",
    "                                                       depletion=True,\n",
    "                                                       use_pseudo_counts=True,\n",
    "                                                       length_variable_region=len_variable,\n",
    "                                                       neg_ctrl_sequencing_depth=seq_depth_stats[neg_ctrl][0],\n",
    "                                                       test_condition_sequencing_depth=seq_depth_stats[base][0],\n",
    "                                                       reverse_complement=False,\n",
    "                                                       bc_trim_n_left=False,\n",
    "                                                       bc_trim_n_right=False,\n",
    "                                                       weblogo_graph_title=False,\n",
    "                                                       weblogo_x_axis_ticks=False,\n",
    "                                                       out_dir=out_dir\n",
    "                                                      )\n",
    "    fold_dfs[base] = fold_df\n",
    "    freq_dfs[base] = freq_df\n",
    "    count_dfs[base] = count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GET CONDFIDENCE INTERVALS OF NEGATIVE CONTROLS ####\n",
    "\"\"\"\n",
    "- Use the non-targeting, negative controls (Amy3NTR1W1_S3, Amy2NTWT_S2) to establish\n",
    "  a threshold for significantly depelted PAMs that are outside the 99.999999% CI for noise\n",
    "- Establish CI's with bootstrapping\n",
    "\"\"\"\n",
    "\n",
    "ci_filter_dict = {\"Amy5TR1W1_S5\":\"Amy3NTR1W1_S3\",\n",
    "                  \"Amy4TWT_S4\":\"Amy2NTWT_S2\"}\n",
    "alpha = 10**-6\n",
    "cis = {}\n",
    "\n",
    "for sample,base in ci_filter_dict.items():\n",
    "    print(base)\n",
    "    ci = nonparametric_ci_of_mean(count_dfs[base].Log2_Fold_Change, \n",
    "                                  n_iterations = 100000, \n",
    "                                  alpha = alpha,\n",
    "                                  mean = False\n",
    "                                 )\n",
    "    cis[sample] = ci\n",
    "    \n",
    "cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be1487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### GENERATE LOGOS FOR STATISTICALLY SIGNIFICANT DEPELTION ####\n",
    "\"\"\"\n",
    "- Build logos from PAMs with L2FC Depletion > 99.999999% CI for Noise in respective non-targeting condition\n",
    "\"\"\"\n",
    "\n",
    "for base in ['Amy5TR1W1_S5', 'Amy4TWT_S4']: \n",
    "    test_condition_pam_file = f\"{results_dir}{base}_matches.txt\"\n",
    "    neg_ctrl = control_dict[base]\n",
    "    neg_ctrl_pam_file = f\"{results_dir}{neg_ctrl}_matches.txt\"\n",
    "    significant_fold_change = -1*cis[base]\n",
    "    \n",
    "    ## GET PAM FOLDCHANGES\n",
    "    fold_df, freq_df, count_df = pam_fold_change_logos(neg_ctrl_pam_file, \n",
    "                                                       test_condition_pam_file,\n",
    "                                                       fold_change_magnitudes=[significant_fold_change], #log2fC\n",
    "                                                       depletion=True,\n",
    "                                                       use_pseudo_counts=True,\n",
    "                                                       length_variable_region=len_variable,\n",
    "                                                       neg_ctrl_sequencing_depth=seq_depth_stats[neg_ctrl][0],\n",
    "                                                       test_condition_sequencing_depth=seq_depth_stats[base][0],\n",
    "                                                       reverse_complement=False,\n",
    "                                                       bc_trim_n_left=False,\n",
    "                                                       bc_trim_n_right=False,\n",
    "                                                       weblogo_graph_title=False,\n",
    "                                                       weblogo_x_axis_ticks=False,\n",
    "                                                       out_dir=out_dir\n",
    "                                                      )\n",
    "    fold_dfs[base] = fold_df\n",
    "    freq_dfs[base] = freq_df\n",
    "    count_dfs[base] = count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GET CONSENSUS MOTIFS ####\n",
    "# FASTAS WITH SIGNIFICANTLY DEPLETED PAMs\n",
    "sig_fasta_R1W1 = f\"{pwd}Logo_Output/Weblogo_Amy5TR1W1_S5_matches_vs_Amy1Libonly_S1_matches_FC0Pt0929.fa\"\n",
    "sig_fasta_WT = f\"{pwd}Logo_Output/Weblogo_Amy4TWT_S4_matches_vs_Amy1Libonly_S1_matches_FC0Pt1003.fa\"\n",
    "\n",
    "# iGeo\n",
    "r1w1_reads = get_fasta_seqs(sig_fasta_R1W1)\n",
    "m_r1w1 = motifs.create(r1w1_reads)\n",
    "print(\"R1W1 Consenus:\", m_r1w1.degenerate_consensus)\n",
    "\n",
    "# WT GEO\n",
    "wt_reads = get_fasta_seqs(sig_fasta_WT)\n",
    "m_wt = motifs.create(wt_reads)\n",
    "print(\"WT Consenus:\", m_wt.degenerate_consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fce6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAM_Depletion",
   "language": "python",
   "name": "pam_depletion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
